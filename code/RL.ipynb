{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8ee70-1d0b-4291-a704-bb580c447f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mhcflurry import Class1AffinityPredictor\n",
    "import pipeline \n",
    "import tcrgp\n",
    " \n",
    "mhcflurry_model = Class1AffinityPredictor.load()\n",
    "classificator = pipeline.load_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf059e-9fd0-4a0f-ad9c-b50511fe1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants\n",
    "AMINO_ACIDS = \"ARNDCEQGHILKMFPSTWYV\"\n",
    "NUM_AMINO_ACIDS = len(AMINO_ACIDS)\n",
    "MIN_LENGTH = 8\n",
    "MAX_LENGTH = 12\n",
    "MHC_LENGTH = 34  \n",
    "TCR_MAX_LENGTH = 20  \n",
    "NUM_EPISODES = 10000\n",
    "MAX_STEPS_PER_EPISODE = 100\n",
    "REWARD_THRESHOLD = 0.8\n",
    "MAX_ACTIONS = NUM_AMINO_ACIDS * MAX_LENGTH\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence, alphabet=AMINO_ACIDS, max_length=MAX_LENGTH):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    one_hot = torch.zeros(max_length, len(alphabet))\n",
    "    for i, char in enumerate(sequence[:max_length]):\n",
    "        one_hot[i, char_to_int[char]] = 1\n",
    "    return one_hot.flatten()\n",
    "\n",
    "def encode_mhc_sequence(mhc_symbol, mhc_mapping):\n",
    "    mhc_sequence = mhc_mapping.get(mhc_symbol, \"Default_Sequence\")\n",
    "    return one_hot_encode(mhc_sequence, alphabet=AMINO_ACIDS, max_length=MHC_LENGTH)    \n",
    "\n",
    "def encode_tcr_sequence(tcr_sequence):\n",
    "    return one_hot_encode(tcr_sequence, max_length=TCR_MAX_LENGTH)\n",
    "\n",
    "def decode_state(state, alphabet=AMINO_ACIDS, max_length=MAX_LENGTH):\n",
    "    state = state.reshape(-1, len(alphabet))\n",
    "    peptide_sequence = \"\"\n",
    "    for i in range(min(max_length, state.shape[0])):\n",
    "        aa_index = torch.argmax(state[i]).item()\n",
    "        peptide_sequence += alphabet[aa_index]\n",
    "    return peptide_sequence\n",
    "\n",
    "class PeptideQNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(PeptideQNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def calculate_mhc_rewards(peptide_sequence, mhc_symbols):\n",
    "    # Vectorized MHC reward calculation\n",
    "    predicted_ic50s = mhcflurry_model.predict([peptide_sequence] * len(mhc_symbols), mhc_symbols)\n",
    "    rewards = 1.0 - (np.array(predicted_ic50s) / 50000)\n",
    "    return rewards\n",
    "\n",
    "def calculate_tcr_reward(peptide_sequence, tcr_sequences):\n",
    "    rewards = []\n",
    "    for tcr_sequence in tcr_sequences:\n",
    "        tcr_predict = tcrgp.predict([peptide_sequence], [tcr_sequences])\n",
    "        predicted_tcr = tcr_predict[0]\n",
    "        rewards.append(predicted_tcr)\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "def calculate_classification_reward(peptide_sequence):\n",
    "    peptide_sequence = [peptide_sequence]  \n",
    "    probabilities = classifier.predict_proba(peptide_sequence)\n",
    "    class_1_probabilities = [prob[1] for prob in probabilities]\n",
    "    return class_1_probabilities\n",
    "\n",
    "\n",
    "def calculate_best_mhc_tcr_reward(peptide_sequence, mhc_symbols, tcr_sequences):\n",
    "    # Preallocate arrays for MHC and TCR rewards\n",
    "    mhc_rewards = np.empty(len(mhc_symbols))\n",
    "    tcr_rewards = np.empty(len(tcr_sequences))\n",
    "\n",
    "    # Calculate rewards for each MHC symbol\n",
    "    for i, mhc_symbol in enumerate(mhc_symbols):\n",
    "        mhc_rewards[i] = calculate_mhc_reward(peptide_sequence, mhc_symbol)\n",
    "\n",
    "    # Calculate rewards for each TCR sequence\n",
    "    for j, tcr_sequence in enumerate(tcr_sequences):\n",
    "        tcr_rewards[j] = calculate_tcr_reward(peptide_sequence, tcr_sequence)\n",
    "\n",
    "    # Calculate total rewards by multiplying MHC and TCR rewards\n",
    "    total_rewards_matrix = mhc_rewards[:, np.newaxis] * tcr_rewards  # Broadcasting multiplication\n",
    "\n",
    "    # Find the index of the maximum total reward\n",
    "    max_reward_index = np.unravel_index(np.argmax(total_rewards_matrix), total_rewards_matrix.shape)\n",
    "    best_mhc = mhc_symbols[max_reward_index[0]]\n",
    "    best_tcr = tcr_sequences[max_reward_index[1]]\n",
    "    best_reward = total_rewards_matrix[max_reward_index]\n",
    "\n",
    "    # Extract the highest individual MHC and TCR rewards\n",
    "    individual_mhc_reward = np.max(mhc_rewards)\n",
    "    individual_tcr_reward = np.max(tcr_rewards)\n",
    "\n",
    "    return best_reward, best_mhc, best_tcr, individual_mhc_reward, individual_tcr_reward\n",
    "\n",
    "\n",
    "\n",
    "def compute_reward(peptide_sequence, mhc_symbol, tcr_sequences):\n",
    "    classification_reward = calculate_classification_reward(peptide_sequence)\n",
    "    if classification_reward < 0.5:\n",
    "        return 0, None, None, 0, 0\n",
    "    else:\n",
    "        # Use the updated function to get all necessary reward values\n",
    "        best_reward, best_mhc, best_tcr, individual_mhc_reward, individual_tcr_reward = calculate_best_mhc_tcr_reward(peptide_sequence, [mhc_symbol], tcr_sequences)\n",
    "        return best_reward, best_mhc, best_tcr, individual_mhc_reward, individual_tcr_reward\n",
    "        \n",
    "def modify_peptide(peptide_sequence, action):\n",
    "    sequence_length = len(peptide_sequence)\n",
    "    position = action // NUM_AMINO_ACIDS\n",
    "    new_aa = AMINO_ACIDS[action % NUM_AMINO_ACIDS]\n",
    "\n",
    "    if position < sequence_length:\n",
    "        peptide_sequence = peptide_sequence[:position] + new_aa + peptide_sequence[position + 1:]\n",
    "    elif sequence_length < MAX_LENGTH:\n",
    "        peptide_sequence = peptide_sequence[:position] + new_aa + peptide_sequence[position:]\n",
    "    return peptide_sequence\n",
    "    \n",
    "def select_action(state, q_network, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randrange(NUM_AMINO_ACIDS * MAX_LENGTH)\n",
    "    with torch.no_grad():\n",
    "        return q_network(state).max(0)[1].item()\n",
    "\n",
    "def perform_action(action, state, mhc_symbol, tcr_sequence, mhc_mapping):\n",
    "    peptide_sequence = decode_state(state[:NUM_AMINO_ACIDS * MAX_LENGTH])\n",
    "    new_peptide_sequence = modify_peptide(peptide_sequence, action) if action < MAX_ACTIONS else peptide_sequence\n",
    "\n",
    "    total_reward, best_mhc, best_tcr, individual_mhc_reward, individual_tcr_reward = compute_reward(new_peptide_sequence, mhc_symbol, [tcr_sequence])\n",
    "    new_encoded_peptide = one_hot_encode(new_peptide_sequence)\n",
    "    encoded_mhc = encode_mhc_sequence(mhc_symbol, mhc_mapping)\n",
    "    encoded_tcr = encode_tcr_sequence(tcr_sequence)\n",
    "\n",
    "    new_state = torch.cat([new_encoded_peptide, encoded_mhc, encoded_tcr], dim=0)\n",
    "    return new_state, total_reward, best_mhc, best_tcr, individual_mhc_reward, individual_tcr_reward\n",
    "\n",
    "\n",
    "def needleman_wunsch_normalized(seq1, seq2, match=3, mismatch=1, gap=0):\n",
    "    def calculate_max_score(seq1, seq2, match, mismatch, gap):\n",
    "        # Calculate the maximum possible score\n",
    "        max_score = max(len(seq1), len(seq2)) * match\n",
    "        return max_score\n",
    "\n",
    "    # Create a matrix to store alignment scores\n",
    "    matrix = np.zeros((len(seq1) + 1, len(seq2) + 1))\n",
    "\n",
    "    # Initialize the first row and first column with gap penalties\n",
    "    for i in range(len(seq1) + 1):\n",
    "        matrix[i][0] = i * gap\n",
    "    for j in range(len(seq2) + 1):\n",
    "        matrix[0][j] = j * gap\n",
    "\n",
    "    # Fill in the matrix\n",
    "    for i in range(1, len(seq1) + 1):\n",
    "        for j in range(1, len(seq2) + 1):\n",
    "            match_score = matrix[i-1][j-1] + (match if seq1[i-1] == seq2[j-1] else mismatch) \n",
    "            delete_score = matrix[i-1][j] + gap\n",
    "            insert_score = matrix[i][j-1] + gap\n",
    "            matrix[i][j] = max(match_score, delete_score, insert_score)\n",
    "\n",
    "    # Calculate the normalized similarity score\n",
    "    similarity_score = matrix[len(seq1)][len(seq2)] / calculate_max_score(seq1, seq2, match, mismatch, gap)\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "\n",
    "def train_q_network(mhc_mapping, tcr_sequence_list, max_selected_peptides=100):\n",
    "    input_size = (NUM_AMINO_ACIDS * MAX_LENGTH) + (NUM_AMINO_ACIDS * MHC_LENGTH) + (NUM_AMINO_ACIDS * TCR_MAX_LENGTH)\n",
    "    output_size = MAX_ACTIONS\n",
    "    learning_rate = 0.001\n",
    "    epsilon_start = 1.0\n",
    "    epsilon_end = 0.01\n",
    "    epsilon_decay = 300\n",
    "\n",
    "    q_network = PeptideQNetwork(input_size, output_size)\n",
    "    optimizer = optim.Adam(q_network.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    peptide_rewards = {}\n",
    "    data_buffer = []\n",
    "    mhc_usage = {}\n",
    "    tcr_usage = {}\n",
    "    \n",
    "    # Helper function to calculate similarity with existing peptides\n",
    "    def is_too_similar(new_peptide, peptide_rewards, threshold):\n",
    "        for existing_peptide in peptide_rewards.keys():\n",
    "            if needleman_wunsch_normalized(new_peptide, existing_peptide) > threshold:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    for episode in tqdm(range(NUM_EPISODES), desc=\"Training Episodes\"):\n",
    "        initial_peptide = ''.join(random.choices(AMINO_ACIDS, k=random.randint(MIN_LENGTH, MAX_LENGTH)))\n",
    "        encoded_peptide = one_hot_encode(initial_peptide)\n",
    "\n",
    "        mhc_symbol = random.choice(list(mhc_mapping.keys()))\n",
    "        encoded_mhc = encode_mhc_sequence(mhc_symbol, mhc_mapping)\n",
    "\n",
    "        tcr_sequence = random.choice(tcr_sequence_list)\n",
    "        encoded_tcr = encode_tcr_sequence(tcr_sequence)\n",
    "\n",
    "        state = torch.cat([encoded_peptide, encoded_mhc, encoded_tcr], dim=0)\n",
    "\n",
    "        for t in range(MAX_STEPS_PER_EPISODE):\n",
    "            epsilon = epsilon_end + (epsilon_start - epsilon_end) * math.exp(-1. * t / epsilon_decay)\n",
    "            state_tensor = torch.FloatTensor(state)\n",
    "            action = select_action(state_tensor, q_network, epsilon)\n",
    "\n",
    "            new_state, total_reward, best_mhc, best_tcr, individual_mhc_reward, individual_tcr_reward = perform_action(action, state_tensor, mhc_symbol, tcr_sequence, mhc_mapping)\n",
    "            new_peptide = decode_state(new_state[:NUM_AMINO_ACIDS * MAX_LENGTH])\n",
    "\n",
    "            new_state_tensor = torch.FloatTensor(new_state)\n",
    "            current_q = q_network(state_tensor)[action].unsqueeze(0)\n",
    "            max_next_q = q_network(new_state_tensor).max().item()\n",
    "            expected_q = total_reward + (0.99 * max_next_q)\n",
    "            loss = loss_fn(current_q, torch.tensor([expected_q], dtype=torch.float))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            state = new_state\n",
    "\n",
    "            data_buffer.append((episode, t, new_peptide, total_reward, loss.item(), best_mhc, best_tcr, individual_mhc_reward, individual_tcr_reward))\n",
    "\n",
    "            if total_reward >= REWARD_THRESHOLD and mhc_usage.get(best_mhc, 0) < 10 and tcr_usage.get(best_tcr, 0) < 10:\n",
    "                if new_peptide not in peptide_rewards or peptide_rewards[new_peptide]['total_reward'] < total_reward:\n",
    "                    if not is_too_similar(new_peptide, peptide_rewards, SIMILARITY_THRESHOLD):\n",
    "                        peptide_rewards[new_peptide] = {\n",
    "                            'total_reward': total_reward,\n",
    "                            'mhc_reward': individual_mhc_reward,\n",
    "                            'mhc_protein': best_mhc,\n",
    "                            'tcr_reward': individual_tcr_reward,\n",
    "                            'tcr_sequence': best_tcr\n",
    "                        }\n",
    "                        mhc_usage[best_mhc] = mhc_usage.get(best_mhc, 0) + 1\n",
    "                        tcr_usage[best_tcr] = tcr_usage.get(best_tcr, 0) + 1\n",
    "\n",
    "            if len(data_buffer) >= 1000:\n",
    "                with open(\"training_log_dict.txt\", \"a\") as file:\n",
    "                    for data in data_buffer:\n",
    "                        file.write(f\"{','.join(map(str, data))}\\n\")\n",
    "                data_buffer.clear()\n",
    "\n",
    "            if len(peptide_rewards) >= max_selected_peptides:\n",
    "                print(f\"Reached {max_selected_peptides} selected peptides. Terminating training.\")\n",
    "                break\n",
    "\n",
    "        if len(peptide_rewards) >= max_selected_peptides:\n",
    "            break\n",
    "\n",
    "    with open(\"training_log_dict.txt\", \"a\") as file:\n",
    "        for data in data_buffer:\n",
    "            file.write(f\"{','.join(map(str, data))}\\n\")\n",
    "\n",
    "    return peptide_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f817cbe-72aa-4e4e-afae-3b2f36c8a1de",
   "metadata": {},
   "source": [
    "#### Synthetic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52c7c2-b1e7-4860-84a1-3ff7e059c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = pd.read_csv('/home/sjurc/Documents/python/neoantigen/automate/results/synthetic_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939823a-42dc-464b-94e2-ff2eb5664665",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhc_mapping = dict(zip(synth['mhc_molecule'], synth['sequence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e5dca-1c07-4702-946e-5010e395490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhc_mapping = dict(list(mhc_mapping.items()))\n",
    "tcr_sequences = tcr_sequence_list\n",
    "\n",
    "\n",
    "peptides_synth = train_q_network(mhc_mapping, tcr_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7e576-af16-4299-aa7f-fbaab7402f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peptides_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f6152-73f7-404f-aab2-ebd963422bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "mhc_counter = Counter()\n",
    "tcr_seq_counter = Counter()\n",
    "\n",
    "for key in peptides_synth:\n",
    "    mhc_counter[peptides_synth[key]['mhc_protein']] += 1\n",
    "    tcr_seq_counter[peptides_synth[key]['tcr_sequence']] += 1\n",
    "\n",
    "mhc_counter, tcr_seq_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140c109-e6a6-40ed-a283-8bf078d98076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
